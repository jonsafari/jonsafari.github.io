<html>
    <head>
	<title>Seminar on Statistical Language Modeling</title>
	<link rel="stylesheet" href="../../../style.css">
    </head>
    <body style="width:650px; text-align:justify; margin-left:auto; margin-right:auto; line-height:135%">
		<a href="http://ling.ohio-state.edu/~jonsafari">[Home]</a>
	<br> <br> <br>

	<a href="http://www.coli.uni-saarland.de"> <img src="../../../images/uni-saarland.png" height="80" alt="UniversitÃ¤t des Saarlandes"> </a>

	<h1>Graduate Seminar on <br/>Statistical Language Modeling</h1>
	<h3>Instructor: Dr. <a href="http://jon.dehdari.org">Jon Dehdari</a></h3>

	<p>
	Statistical language modeling, which provides probabilities for linguistic utterances,
	is a vital component in machine translation, automatic speech recognition,
	information retrieval, and many other language technologies. In this
	seminar we will discuss different types of language models and how they are
	used in various applications. The language models include <i>n</i>-gram- (including
	various smoothing techniques), skip-, class-, factored-, topic-, and
	neural-network-based approaches. We also will look at how these perform on
	different language typologies and at different scales of training set sizes.
	</p>
	<p>
	This seminar will be followed by a project seminar where you will work in small
	groups to identify a shortcoming of an existing language model, make a novel
	modification to overcome the shortcoming, compare experimental results of your
	new method with the existing baseline, and discuss the results. It'll be fun.
	</p>

	<h2><b><a href="syllabus.pdf">Syllabus</a></b></h2>

	<h2>Topics</h2>
	<p>
	<ol>
		<li><a href="pres_01_lm_overview_and_ngram.pdf">Overview of Language Models, including <i>n</i>-gram models</a></li>
		<li><a href="pres_03_cache_and_skip.pdf">Cache and Skip Language Models</a></li>
		<li><a href="pres_04_factored_lm.pdf">Factored Language Models</a></li>
		<li><a href="pres_05_sentence_mixture_models.pdf">Sentence Mixture Models</a></li>
		<li>PLSA/Topic-based Language Models: <a href="pres_06a_topic_model_lm.pdf">A</a> <a href="pres_06b_topic_model_lm.pdf">B</a></li>
		<li><a href="pres_07_bilingual_lm.pdf">Bilingual Language Models</a></li>
		<li><a href="pres_08_ffnnet_lm.pdf">Feedforward Neural Network Language Models</a>:  Derivatives: <a href="pres_08_ffnnet_lm_derivatives_bengio.pdf">A</a> <a href="pres_08_ffnnet_lm_derivatives_tomato.jpg">B</a></li>
		<li><a href="pres_09_rnnlm.pdf">Recurrent (viz. Elman) Neural Network Language Models</a></li>
		<li><a href="pres_10_big_lms.pdf">Big Language Models</a></li>
	</ol>
	</p>

	<h2>Assignments</h2>
	<p>
	<ol>
		<li><a href="assignment_01.pdf">Assignment 1</a></li>
		<li><a href="assignment_02.pdf">Assignment 2</a></li>
	</ol>
	</p>

	<h2>External Links</h2>
	<p>
	<ul>
		<li><a href="https://en.wikipedia.org/wiki/Language_model#External_links">List of Language Modeling Software</a></li>
		<li>Free Corpora:</li>
		<ul>
			<li><a href=" http://www.statmt.org/wmt14/translation-task.html#download">WMT 2014</a>, especially News Crawl under "Monolingual language model training data"</li>
			<li><a href="http://aclweb.org/aclwiki/index.php?title=List_of_resources_by_language">ACL Wiki, "Resources by Language"</a></li>
		</ul>
		<li>Corpus Processing Tools:</li>
		<ul>
			<li><a href="http://jon.dehdari.org/corpus_tools">http://jon.dehdari.org/corpus_tools</a></li>
			<li><a href="https://github.com/kpu/preprocess">https://github.com/kpu/preprocess</a></li>
		</ul>
	</ul>
	</p>


	<br>
	<br>
    </body>
</html>
